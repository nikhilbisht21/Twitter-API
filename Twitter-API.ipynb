{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Search/Streaming API\n",
    "\n",
    "\n",
    "This API is for fetching and storing the target tweets with metadata(e.g. modi,AbkiBarModiSarkar,ModiForPM etc)\n",
    "### Objectives\n",
    "<ul>\n",
    "<li>Trigger a twitter search/stream for recent high traffic events.\n",
    "\n",
    "    </li>\n",
    "<li> \n",
    "    Return stored tweets and their metadata based on applied filters/search.\n",
    "    </li>\n",
    "    <li> \n",
    "    Export data to csv file\n",
    "    </li>\n",
    "</ul>\n",
    "\n",
    "#### Basic structure diagram of API\n",
    "<img src='twitter.png'>\n",
    "\n",
    "### Specifications\n",
    "#### Programming language : Python\n",
    "#### Database : MongoDB(NoSQL Database)\n",
    "#### Data fetching method : Searching and Streaming\n",
    "\n",
    "### Prerequisite\n",
    "#### Python modules\n",
    "<ul>\n",
    "    <li>python-twitter</li>\n",
    "    <li>pymongo</li>\n",
    "    </ul>\n",
    "    \n",
    "#### Twitter authetication keys\n",
    "In order to fetch the data from twitter we have to send a connection request to twitter servers with header. \n",
    "This header contains authetication parameters which are basically authetication tokens provided by twitter.\n",
    "Following keys are needed in order to use the api:\n",
    "<ul>\n",
    "    <li>consumer_key</li>\n",
    "    <li>access_token_key</li>\n",
    "    <li>consumer_secret</li>\n",
    "    <li>access_token_secret</li>\n",
    "</ul>\n",
    "\n",
    "#### MongoDB\n",
    "There are two ways to work on mongoDB, either it could be installed directly in our local system or use the free cloud database service.A URI is needed in case free cloud database is used.<br>\n",
    "See resources for further details.\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# API Functions\n",
    "\n",
    "<ul>\n",
    "    <li>configure()</li>\n",
    "    <li>exportFilter()</li>\n",
    "    <li>exportToCSV()</li>\n",
    "    <li>filterDateTime()</li>\n",
    "    <li>filterTweets()</li>\n",
    "    <li>initialize()</li>\n",
    "    <li>search()</li>\n",
    "    <li>searchTweets()</li>\n",
    "    <li>sortTweets()</li>\n",
    "    <li>streamTweets()</li>\n",
    "    <li>tweetBook_object.next()</li>\n",
    "    <li>tweetBook_object.previous()</li>\n",
    "    <li>verify()</li>\n",
    "    <li>viewBook()</li>   \n",
    "    </ul>\n",
    "    \n",
    "# Getting Started\n",
    "\n",
    "\n",
    "<b>1.</b> Import twitter_api as tap<br>\n",
    "<b>2.</b> tap.configure(<b>consumer_key</b>='consumer_key',<b>access_token_key</b>='access_token_key',<b>tap.consumer_secret</b>='consumer_secret',\n",
    "<b>tap.access_token_secret</b>='access_token_secret',<b>uri</b>='uri')\n",
    "<br><b>3.</b> tap.initialize()\n",
    "<br><b>4.</b> tap.searchTweets(keywords=['modi','AbkiBarModiSarkar','ModiForPM'],deliminiter='or',count=1000)\n",
    "    <b>OR</b> tap.streamTweets(keywords=['modi','AbkiBarModiSarkar','ModiForPM'],deliminiter='or',count=1000)\n",
    " #### Now api is ready to be use. For further details check documentation and references.\n",
    "\n",
    "\n",
    "### References\n",
    "Standard Searching https://developer.twitter.com/en/docs/tweets/search/api-reference/get-search-tweets<br>\n",
    "Stream Filtering  https://developer.twitter.com/en/docs/tweets/filter-realtime/guides/basic-stream-parameters<br>\n",
    "Introduction to Tweet JSON https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/intro-to-tweet-json<br>\n",
    "Tweet data dictionaries https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object<br>\n",
    "Link to get application tokens https://apps.twitter.com/<br>\n",
    "Guide to get application tokens https://github.com/bear/python-twitter/blob/master/doc/getting_started.rst<br>\n",
    "Link to the guide to get URI https://docs.mongodb.com/manual/tutorial/atlas-free-tier-setup/<br>\n",
    "Download link to monogoBD https://www.mongodb.com/download-center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twitter\n",
    "import pymongo\n",
    "import pprint as pp\n",
    "import csv,json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intializing the parameters for percent_encode\n",
    "\n",
    "def par():\n",
    "    \"\"\"\n",
    "    par()\n",
    "    \n",
    "    Intializes global variable \"a\" which is used by percent_encode() in string encoding w.r.t twitter standards\n",
    "    \"\"\"\n",
    "    \n",
    "    global a,mon\n",
    "    \n",
    "    a=['0','1','2','3','4','5','6','7','8','9','a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z','A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']\n",
    "    \n",
    "    a.append('_')\n",
    "    a.append('.')\n",
    "    a.append('~')\n",
    "    a.append('-')\n",
    "    \n",
    "    mon={'Jan':1,'Feb':2,'Mar':3,'Apr':4,'May':5,'Jun':6,'Jul':7,'Aug':8,'Sep':9,'Oct':10,'Nov':11,'Dec':12}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Percent Encode Function to encode strings\n",
    "\n",
    "def percent_encode(code):\n",
    "    \"\"\"\n",
    "    percent_encode(code)\n",
    "    \n",
    "    Returns an encoded string according to twitter standards, used while sending search query and getting data from twitter database\n",
    "    \n",
    "    parameters:\n",
    "    1.code(string)\n",
    "    \n",
    "    returns:\n",
    "    An encoded string w.r.t to twitter standards\n",
    "    \"\"\"\n",
    "    \n",
    "    tmp=\"\"\n",
    "    for vb in code:\n",
    "        if vb not in a:\n",
    "            #print(vb)\n",
    "            b=hex(ord(vb)).split('x')\n",
    "            b=b[len(b)-1].upper()\n",
    "            tmp+='%{}'.format(b)\n",
    "        else:\n",
    "            tmp+=vb\n",
    "            \n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the data from tweet for collection\n",
    "\n",
    "\n",
    "def extract(tweet):\n",
    "    \"\"\"\n",
    "    extract(tweet)\n",
    "    \n",
    "    This function extract the details from a single tweet i.e. a dictionary object and stores the minimal details of tweet in...\n",
    "    ..dictionary named as data.\n",
    "    \n",
    "    parameters:\n",
    "    1.tweet(dictionary):\n",
    "        This dictonary contains a single tweet data\n",
    "    \n",
    "    returns:\n",
    "    1.data\n",
    "        Dictionary with minimal detais of a single tweet\n",
    "    2.user\n",
    "        Dictionary with minimal details of tweet's user\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        data={}\n",
    "        data['tweet_id']=tweet['id_str']\n",
    "    \n",
    "        tmp=tweet['created_at'].split(' ')\n",
    "        date='{0} {1} {2}'.format(tmp[5],mon[tmp[1]],tmp[2])\n",
    "        time=tmp[3]\n",
    "        day=tmp[0]\n",
    "        data['created_at']={\n",
    "        'date':date,\n",
    "        'time':time,\n",
    "        'day':day\n",
    "        }\n",
    "        data['lang']=tweet['lang']\n",
    "        data['retweet_count']=tweet['retweet_count']\n",
    "        data['retweeted']=tweet['retweeted']\n",
    "        data['favorite_count']=tweet['favorite_count']\n",
    "        data['favorited']=tweet['favorited']\n",
    "        data['quote_status']=tweet['is_quote_status']\n",
    "        data['place']=tweet['place']\n",
    "        data['text']=tweet['text']\n",
    "        data['truncated']=tweet['truncated']\n",
    "        data['source']=tweet['source'].split('>')[1].split('<')[0]\n",
    "        data['user_id']=tweet['user']['id_str']\n",
    "    \n",
    "        if tweet['in_reply_to_status_id_str']:\n",
    "            data['is_reply']=True\n",
    "        else:\n",
    "            data['is_reply']=False\n",
    "        \n",
    "        data['reply_to']={\n",
    "            \"status_id\":tweet['in_reply_to_status_id_str'],\n",
    "            \"user_id\":tweet['in_reply_to_user_id_str'],\n",
    "            \"user_screen_name\":tweet['in_reply_to_screen_name']\n",
    "        }\n",
    "    \n",
    "        if 'retweeted' in tweet.keys():\n",
    "            data['retweeted']=False\n",
    "        else:\n",
    "            data['retweeted']=True\n",
    "            \n",
    "        data['urls']=[]\n",
    "    \n",
    "        if len(tweet['entities']['urls']) is not 0:\n",
    "            for va in range(len(tweet['entities']['urls'])):\n",
    "                data['urls'].append(tweet['entities']['urls'][va]['expanded_url'])\n",
    "            \n",
    "        data['mentions']=[]\n",
    "    \n",
    "        if len(tweet['entities']['user_mentions']) is not 0:\n",
    "            for va in range(len(tweet['entities']['user_mentions'])):\n",
    "                tmp=tweet['entities']['user_mentions'][va]\n",
    "                data['mentions'].append({'user_id':tmp['id_str'],\n",
    "                                 'name':tmp['name'],\n",
    "                                'screen_name':tmp['screen_name']})\n",
    "            \n",
    "        data['hashtags']=[]\n",
    "    \n",
    "        if len(tweet['entities']['hashtags']) is not 0:\n",
    "            for va in range(len(tweet['entities']['hashtags'])):\n",
    "                data['hashtags'].append('#{0}'.format(tweet['entities']['hashtags'][va]['text']))\n",
    "            \n",
    "        data['media_status']=False\n",
    "        data['media']=[]\n",
    "    \n",
    "    \n",
    "        if 'media' in tweet['entities'].keys():\n",
    "            data['media_status']=True\n",
    "            for va in range(len(tweet['entities']['media'])):\n",
    "                data['media'].append({\n",
    "                    'id':tweet['entities']['media'][va]['id_str'],\n",
    "                    'type':tweet['entities']['media'][va]['type'],\n",
    "                    'url':tweet['entities']['media'][va]['media_url'],\n",
    "                'url_https':tweet['entities']['media'][va]['media_url_https']})   \n",
    "    \n",
    "        if 'extended_entities' in tweet.keys():\n",
    "            data['media_status']=True\n",
    "            for va in range(len(tweet['extended_entities']['media'])):\n",
    "                data['media'].append({\n",
    "                    'id':tweet['extended_entities']['media'][va]['id_str'],\n",
    "                    'type':tweet['extended_entities']['media'][va]['type'],\n",
    "                    'url':tweet['extended_entities']['media'][va]['media_url'],\n",
    "                    'url_https':tweet['extended_entities']['media'][va]['media_url_https']})\n",
    "            \n",
    "    \n",
    "        user={}\n",
    "        user['id']=tweet['user']['id_str']\n",
    "        user['name']=tweet['user']['name']\n",
    "        user['screen_name']=tweet['user']['screen_name']\n",
    "        user['profile_link']=tweet['user']['url']\n",
    "        user['location']=tweet['user']['location']\n",
    "        user['lang']=tweet['user']['lang']\n",
    "        user['description']=tweet['user']['description']\n",
    "        user['followers_count']=tweet['user']['followers_count']\n",
    "        user['friends_count']=tweet['user']['friends_count']\n",
    "        user['favourites_count']=tweet['user']['favourites_count']\n",
    "        user['verified']=tweet['user']['verified']\n",
    "        user['listed_count']=tweet['user']['listed_count']\n",
    "        user['profile_background_image_url']=tweet['user']['profile_background_image_url']\n",
    "        user['profile_background_image_url_https']=tweet['user']['profile_background_image_url_https']\n",
    "        user['profile_image_url']=tweet['user']['profile_image_url']\n",
    "        user['profile_image_url_https']=tweet['user']['profile_image_url_https']\n",
    "        \n",
    "    except:\n",
    "         None \n",
    "        \n",
    "    return data,user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding tweet and user records to database\n",
    "\n",
    "\n",
    "def add_document(db,data,user):\n",
    "    \"\"\"\n",
    "    add_document(db,data,user)\n",
    "    \n",
    "    This function add a tweet to database.\n",
    "    The tweet is divided into two subparts to remove redundancy in database.\n",
    "    Subparts of a single tweet:\n",
    "        1.tweet:\n",
    "            It has the details related to tweet only\n",
    "        2.user:\n",
    "            It has the details about the user of the tweet\n",
    "        tweet,user are saved in different collections in database\n",
    "        \n",
    "    parameters:\n",
    "    1.db:\n",
    "        Instance of the database\n",
    "    2.data:\n",
    "        Dictionary with the information about tweet\n",
    "    3.user:\n",
    "        Dictionary with the information about tweet's user\n",
    "    returns:\n",
    "    An integer value denoting success and failure of adding document to database\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    resa=None\n",
    "    resb=None\n",
    "    \n",
    "    try:\n",
    "        count=db.tweets.find({'tweet_id':data['tweet_id']}).count()\n",
    "        if count is 0:\n",
    "            resa=db.tweets.insert_one(data)\n",
    "            #print(resa.inserted_id)\n",
    "    \n",
    "        count=db.users.find({'id':user['id']}).count()\n",
    "        if count is 0:\n",
    "            resb=db.users.insert_one(user)\n",
    "            #print(res.inserted_id)\n",
    "        \n",
    "        if resa:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class to return paginated tweets\n",
    "\n",
    "class tweetBook:\n",
    "    \"\"\"\n",
    "    tweet class\n",
    "    \n",
    "    tweet class is used to implement pagination of the inforamtion retrieved  from database\n",
    "    \n",
    "    data members:\n",
    "    1.pages(int):\n",
    "        No. of pages in the dictionary(Calculated as total total tweets/tweets per page)\n",
    "    2.data(list):\n",
    "        List to store the records retrieved from database.\n",
    "        Index of list acts as pages for records\n",
    "    3.pointer(int):\n",
    "        Points to the current page of the records\n",
    "    \n",
    "    member functions:\n",
    "    1.__init__(self):\n",
    "        Constructor \n",
    "    2.def assign(self,data,num):\n",
    "        Add limited tweets in a single index of list resulting as a page of records\n",
    "    3.def next(self):\n",
    "        This function increment the pointer thus moving to next page of record\n",
    "    4.def previous(self):\n",
    "        This function decrement the pointer thus moving to previous page of record\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    pages=0\n",
    "    data=[]\n",
    "    pointer=0\n",
    "    \n",
    "    def _init_(self):\n",
    "        self.pages=0\n",
    "        self.pointer=0\n",
    "    \n",
    "    def assign(self,data,num):\n",
    "        \n",
    "        self.pages=self.pages+1\n",
    "        tmp={'tweets':data[0:num],'meta':{'page no':self.pages,'total tweets':num}}\n",
    "        self.data.append(tmp)\n",
    "        \n",
    "    def next(self):\n",
    "        if self.pointer!=self.pages:   \n",
    "            self.pointer=self.pointer+1  \n",
    "        return self.data[self.pointer-1]\n",
    "        #print(self.pointer)\n",
    "    \n",
    "    def previous(self):\n",
    "        if self.pointer!=1:   \n",
    "            self.pointer=self.pointer-1\n",
    "        \n",
    "        if self.pointer is -1:\n",
    "            self.pointer=self.pages\n",
    "            \n",
    "        return self.data[self.pointer-1]\n",
    "        #print(self.pointer)\n",
    "        \n",
    "    def update_meta(self):\n",
    "        for va in self.data:\n",
    "            va['meta']['total pages']=self.pages\n",
    "\n",
    "#ob=tweetBook()\n",
    "#ob.next()\n",
    "#ob.previous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect user details\n",
    "\n",
    "\n",
    "def get_user(db,id):\n",
    "    \"\"\"\n",
    "    get_user(db,id)\n",
    "    \n",
    "    This function returns the user details for a single tweet by fetching user document from database \n",
    "    \n",
    "    parameters:\n",
    "    1.db:\n",
    "        Instance of database\n",
    "    2.id\n",
    "        userid to be matched in the database to get user information\n",
    "        \n",
    "    returns:\n",
    "    A dictionary containing details of the user\n",
    "    \"\"\"\n",
    "    usr=db.users.find({'id':str(id)},{'_id':0})\n",
    "    return next(usr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect tweet details\n",
    "\n",
    "def get_tweet(db,id):\n",
    "    \"\"\"\n",
    "    get_tweet(db,id)\n",
    "    \n",
    "    This function returns the tweet details for a single user by fetching tweet document from database \n",
    "    \n",
    "    parameters:\n",
    "    1.db:\n",
    "        Instance of database\n",
    "    2.id\n",
    "        tweet_id to be matched in the database to get user information\n",
    "        \n",
    "    returns:\n",
    "    A dictionary containing details of the tweets by user\n",
    "    \"\"\"\n",
    "    twt=db.tweets.find({'user_id':str(id)},{'_id':0})\n",
    "    \n",
    "    data=[]\n",
    "    for va in twt:\n",
    "        data.append(va)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating tweet pages\n",
    "\n",
    "def gen_pages(db,twts,limit=32):\n",
    "    \"\"\"\n",
    "    gen_pages(db,twts,limit=32)\n",
    "    \n",
    "    This function is used to implement pagination to the records fetched from the database.\n",
    "    It uses tweet class to form a book like data structure providing with pages.\n",
    "    \n",
    "    parameters\n",
    "    1.db:\n",
    "        Instance of the database\n",
    "    2.twts(dictionary):\n",
    "        Tweet records fetched from the database\n",
    "    2.limit(int)\n",
    "        No. of tweets per page\n",
    "        \n",
    "    returns:\n",
    "    An object of tweet class\n",
    "    Operations which be perfored on this object\n",
    "    next():\n",
    "        Goto next page of tweet book\n",
    "    previous():\n",
    "        Goto previous page of tweet book  \n",
    "    \"\"\"\n",
    "    \n",
    "    i=0\n",
    "    data=[]\n",
    "\n",
    "    ob=tweetBook()\n",
    "\n",
    "    for dat in twts:\n",
    "        \n",
    "        tmp=get_user(db,dat['user_id'])\n",
    "        dat['user']=tmp\n",
    "        \n",
    "        if i==limit:\n",
    "            ob.assign(data,limit)\n",
    "            data.clear()\n",
    "            data.append(dat)\n",
    "            i=1\n",
    "        else:\n",
    "            data.append(dat)\n",
    "            i=i+1\n",
    "\n",
    "    if i>=1:\n",
    "        ob.assign(data,i)\n",
    "        data.clear()\n",
    "        \n",
    "    ob.update_meta()\n",
    "    \n",
    "    return ob\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making Connection to NoSQL Database\n",
    "\n",
    "\n",
    "def database():\n",
    "    \"\"\"\n",
    "    database()\n",
    "    \n",
    "    This function intialize the global instance of the database\n",
    "    \n",
    "    Database: monoDB\n",
    "    Database name: twitter\n",
    "    Collection Names: tweets,user\n",
    "    url: Link of the online database of mongoDB\n",
    "    \n",
    "    Note: To run mongoDB from localhost don't pass any parameter to MongoClient()\n",
    "    \"\"\"\n",
    "    try:\n",
    "        url=None\n",
    "        global db\n",
    "        \n",
    "        try:\n",
    "            data=json.load(open('twitter.json'))\n",
    "            url=data['uri']\n",
    "        except:\n",
    "            url=None\n",
    "        \n",
    "        if url is '':\n",
    "            url=None\n",
    "        \n",
    "        client = pymongo.MongoClient(url)\n",
    "\n",
    "        #Create an object to Connect or create new database(Here database name is \"twitter\" )\n",
    "        db=client.twitter\n",
    "\n",
    "        #Check status\n",
    "        status=db.command(\"serverStatus\")\n",
    "            \n",
    "    except:\n",
    "        print('Error in creating connection with database')\n",
    "        db=None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching in tweets\n",
    "\n",
    "def search(keywords=None,search_by='text'):\n",
    "    \"\"\"\"\n",
    "    search(keyword=None,search_by='text')\n",
    "    \n",
    "    This function is used to perform search operation over the tweet records stored in database\n",
    "    \n",
    "    parameters:\n",
    "    1.keywords(list):\n",
    "        Words to be searched in database\n",
    "    2.search_by(string)\n",
    "        where to search for keywords in database\n",
    "        options:\n",
    "            text\n",
    "            name\n",
    "            screen_name\n",
    "            \n",
    "    returns:\n",
    "    An instance of tweet class\n",
    "    Operations which be perfored on this object\n",
    "    next():\n",
    "        Goto next page of tweet book\n",
    "    previous():\n",
    "        Goto previous page of tweet book  \n",
    "    \"\"\"\n",
    "    \n",
    "    ob=None\n",
    "    count=0\n",
    "    keyword=get_words(keywords)\n",
    "    \n",
    "    try:\n",
    "        db.tweets.drop_indexes()\n",
    "        db.users.drop_indexes()\n",
    "        \n",
    "        if search_by is 'text':\n",
    "            db.tweets.create_index([(search_by,pymongo.TEXT)])\n",
    "            data=db.tweets.find({'$text':{'$search':\"%s\"%keyword}},{'_id':0})\n",
    "            count=data.count()\n",
    "        \n",
    "        if search_by is 'name' or search_by is 'screen_name':\n",
    "            db.users.create_index([(search_by,pymongo.TEXT)])\n",
    "            data=db.users.find({'$text':{'$search':\"\\\"%s\\\"\"%keyword}},{'_id':0})\n",
    "        \n",
    "            if data.count()>0:\n",
    "                usr=next(data)\n",
    "                usr=usr['id']\n",
    "                data=db.tweets.find({'user_id':usr},{'_id':0})\n",
    "                count=data.count()        \n",
    " \n",
    "        if count>0:\n",
    "            print('{0} tweets found'.format(data.count()))\n",
    "            ob=gen_pages(db,data)\n",
    "        else:\n",
    "            print('No tweets found with such %s'%search_by)\n",
    "                                \n",
    "    \n",
    "    except:\n",
    "        print('An error occoured')\n",
    "    \n",
    "    return ob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorting the Tweets by text,favorite_count,retweet_count,date,time,day\n",
    "\n",
    "def sortTweets(sort_by=None,order='asc'):\n",
    "    \"\"\"\n",
    "    sortTweets(sort_by=None,order='asc')\n",
    "    \n",
    "    This function returns the sorted tweets fetched from the database\n",
    "    \n",
    "    parameters:\n",
    "    1.sort_by(string)\n",
    "        Keys on the basis of which record are to be sorted\n",
    "        options:\n",
    "            date\n",
    "            time\n",
    "            day\n",
    "            text\n",
    "            retweet_count\n",
    "            favorite_count\n",
    "    2.order:\n",
    "        Ascending or descending order\n",
    "        options:\n",
    "            asc\n",
    "            des\n",
    "            \n",
    "    returns:\n",
    "    An instance of tweet class\n",
    "    Operations which be perfored on this object\n",
    "    next():\n",
    "        Goto next page of tweet book\n",
    "    previous():\n",
    "        Goto previous page of tweet book  \n",
    "    \"\"\"\n",
    "    try:\n",
    "        if order is 'asc':\n",
    "            order=1\n",
    "        elif order is 'des':\n",
    "            order=-1\n",
    "        \n",
    "        if sort_by in ['date','time','day','text','retweet_count','favorite_count']:\n",
    "            sort_by='created_at.{}'.format(sort_by)\n",
    "        \n",
    "        data=db.tweets.find({},{'_id':0}).sort([(sort_by,order)])\n",
    "   \n",
    "        ob=gen_pages(db,data)\n",
    "    except:\n",
    "        print('An unexpected error occured')\n",
    "    \n",
    "    \n",
    "    return ob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter tweets\n",
    "\n",
    "def filterTweets(filter_by=None,keywords=None,flag=None,value=None):\n",
    "    \"\"\"\n",
    "    filterTweets(filter_by=None,keywords=None,flag=None,value=None)\n",
    "    \n",
    "    This function is used to filter the tweets fetched from the database\n",
    "    \n",
    "    parameters:\n",
    "    1.filter_by(string):\n",
    "        options:\n",
    "            retweet_count\n",
    "            favorite_count\n",
    "            followers_count\n",
    "            friends_count\n",
    "            favourites_count\n",
    "            listed_count\n",
    "            favorited\n",
    "            quote_status\n",
    "            retweeted\n",
    "            truncated\n",
    "            media_status\n",
    "            is_reply\n",
    "            lang\n",
    "            place\n",
    "            text\n",
    "            source\n",
    "            urls\n",
    "            mentions\n",
    "            hashtags\n",
    "            name\n",
    "            screen_name\n",
    "            description\n",
    "    2.keywords(list):\n",
    "        Words to be filter the tweets\n",
    "        Note: To be used with following filter options only:\n",
    "            lang,place,text,source,urls,mentions,hashtags,name,screen_name,description\n",
    "    3.flag(string):\n",
    "        used with filter with string type values\n",
    "        options:\n",
    "            et\n",
    "            lt\n",
    "            gt\n",
    "            lte\n",
    "            gte\n",
    "            ne\n",
    "         Note: To be used with following filter options only: \n",
    "             retweet_count,favorite_count,followers_count,friends_count,favourites_count,listed_count\n",
    "    4.value(int,bool)\n",
    "        values for the filter\n",
    "        Note: To be used with following filter options only: \n",
    "            Integer value: retweet_count,favorite_count,followers_count,friends_count,favourites_count,listed_count'\n",
    "            Bool value: favorited','quote_status','retweeted','truncated','media_status','is_reply\n",
    "    \n",
    "    returns:\n",
    "    An instance of tweet class\n",
    "    Operations which be perfored on this object\n",
    "    next():\n",
    "        Goto next page of tweet book\n",
    "    previous():\n",
    "        Goto previous page of tweet book  \n",
    "    \"\"\"\n",
    "    \n",
    "    db.tweets.drop_indexes()\n",
    "    db.users.drop_indexes()\n",
    "    fl=0\n",
    "    obj=None\n",
    "    \n",
    "    if flag:\n",
    "        sym='$%s'%flag\n",
    "    \n",
    "    if keywords:\n",
    "        st=get_words(keywords)\n",
    "        \n",
    "    #print(flag,st)\n",
    "        \n",
    "    try:\n",
    "        if filter_by in ['retweet_count','favorite_count']:\n",
    "            if flag is 'et':\n",
    "                data=db.tweets.find({filter_by:value},{'_id':0})\n",
    "            else:\n",
    "                data=db.tweets.find({filter_by:{sym:value}},{'_id':0})\n",
    "        elif filter_by in ['followers_count','friends_count','favourites_count','listed_count']:\n",
    "            data=db.users.find({filter_by:{sym:value}},{'_id':0})\n",
    "            data=getTweets(db,data)\n",
    "            fl=1\n",
    "        elif filter_by in ['favorited','quote_status','retweeted','truncated','media_status','is_reply']:\n",
    "            data=db.tweets.find({filter_by:value},{'_id':0})\n",
    "        elif filter_by is'verified':\n",
    "            data=db.users.find({filter_by:value},{'_id':0})\n",
    "            data=getTweets(db,data)\n",
    "            fl=1\n",
    "        elif filter_by is'source':\n",
    "            db.tweets.create_index([(filter_by,pymongo.TEXT)])\n",
    "            data=db.tweets.find({'$text':{'$search':\"{0}\".format(st)}})\n",
    "        elif filter_by in ['lang','place','text','source','urls','mentions','hashtags']:\n",
    "            db.tweets.create_index([(filter_by,pymongo.TEXT)])\n",
    "            if flag is 'exact':\n",
    "                data=db.tweets.find({'$text':{'$search':\"\\\"{0}\\\"\".format(st)}})\n",
    "            elif flag is 'contains':\n",
    "                data=db.tweets.find({'$text':{'$search':\"{0}\".format(st)}})\n",
    "            elif flag is 'starts':\n",
    "                data=db.tweets.find({filter_by:{'$regex':'^%s'%st}})\n",
    "            elif flag is 'ends':\n",
    "                data=db.tweets.find({filter_by:{'$regex':'%s$'%st}})\n",
    "        elif filter_by in ['name','screen_name','description']:\n",
    "            db.users.create_index([(filter_by,pymongo.TEXT)])\n",
    "            if flag is 'exact':\n",
    "                data=db.users.find({'$text':{'$search':\"\\\"{0}\\\"\".format(st)}})\n",
    "            elif flag is 'contains':\n",
    "                data=db.users.find({'$text':{'$search':\"{0}\".format(st)}})\n",
    "            elif flag is 'starts':\n",
    "                data=db.users.find({filter_by:{'$regex':'^%s'%st}})\n",
    "            elif flag is 'ends':\n",
    "                data=db.users.find({filter_by:{'$regex':'%s$'%st}})\n",
    "            data=getTweets(db,data)\n",
    "            fl=1\n",
    "        \n",
    "        \n",
    "        if fl is 1 and len(data)>0:\n",
    "            print('{0} tweets matched'.format(len(data)))\n",
    "            obj=gen_pages_b(db,data)\n",
    "        elif data.count()>0:\n",
    "            print('{0} tweets matched'.format(data.count()))\n",
    "            obj=gen_pages(db,data)\n",
    "        else:\n",
    "            print('No tweets found with %s filter'%filter_by)\n",
    "    except:\n",
    "        print('An unexpected error occured, see documentation to know allowed parameters')\n",
    "    \n",
    "    return obj        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating tweet pages\n",
    "\n",
    "def gen_pages_b(db,twts,limit=32):\n",
    "    \"\"\"\n",
    "    gen_pages_b(db,twts,limit=32)\n",
    "    \n",
    "    This function is used to implement pagination to the records fetched from the database.\n",
    "    It uses tweet class to form a book like data structure providing with pages.\n",
    "    \n",
    "    parameters\n",
    "    1.db:\n",
    "        Instance of the database\n",
    "    2.twts(dictionary):\n",
    "        Tweet records fetched from the database\n",
    "    2.limit(int)\n",
    "        No. of tweets per page\n",
    "        \n",
    "    returns:\n",
    "    An object of tweet class\n",
    "    Operations which be perfored on this object\n",
    "    next():\n",
    "        Goto next page of tweet book\n",
    "    previous():\n",
    "        Goto previous page of tweet book  \n",
    "    \"\"\"\n",
    "    \n",
    "    i=0\n",
    "    data=[]\n",
    "\n",
    "    ob=tweetBook()\n",
    "\n",
    "    for dat in twts:\n",
    "        if i==limit:\n",
    "            ob.assign(data,limit)\n",
    "            data.clear()\n",
    "            data.append(dat)\n",
    "            i=1\n",
    "        else:\n",
    "            data.append(dat)\n",
    "            i=i+1\n",
    "\n",
    "    if i>=1:\n",
    "        ob.assign(data,i)\n",
    "        data.clear()\n",
    "        \n",
    "    ob.update_meta()\n",
    "    \n",
    "    return ob\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all tweets\n",
    "\n",
    "def getTweets(db,dat):\n",
    "    \"\"\"\n",
    "    gettweets(db,data)\n",
    "    \n",
    "    This function returns the tweets by the a particular user \n",
    "    \n",
    "    parameters:\n",
    "    1.db:\n",
    "        Instance of database\n",
    "    2.data(dictionary)\n",
    "        User details\n",
    "        \n",
    "    returns:\n",
    "    A dictionary with tweets by a user\n",
    "    \"\"\"\n",
    "    \n",
    "    data=[]\n",
    "    for var in dat:\n",
    "        twts=db.tweets.find({'user_id':var['id']},{'_id':0})\n",
    "        for va in twts:\n",
    "            va['user']=var\n",
    "            data.append(va)\n",
    "            \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine keywords for filter\n",
    "\n",
    "def get_words(txt=[],delt='and'):\n",
    "    \"\"\"\n",
    "    get_words(txt=[],delt='and')\n",
    "    \n",
    "    Combine the values of a list into a string on the basis of operation needed\n",
    "    \n",
    "    parameters:\n",
    "    1.txt(list)\n",
    "        list of values to be combined\n",
    "    2.del(string)\n",
    "        Delinimter\n",
    "        options:\n",
    "            and\n",
    "            or\n",
    "    \n",
    "    returns:\n",
    "    A string of combines list values\n",
    "    \"\"\"\n",
    "    dt=''\n",
    "    \n",
    "    if delt is 'or':\n",
    "        dl=','\n",
    "    else:\n",
    "        dl=' '\n",
    "    \n",
    "    for var in txt:\n",
    "        dt+='%s%s'%(str(var),dl)\n",
    "    \n",
    "    return dt[0:len(dt)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data fetching through searching\n",
    "\n",
    "def searchTweets(keywords=[],deliminiter='and',count=100):\n",
    "    \"\"\"\n",
    "    searchTweets(keywords=[],deliminiter='and',count=100)\n",
    "    \n",
    "    This function fecth the tweets from the twitter's database with standard search protocol defined by twitter.\n",
    "    Connection will closed by the twitter server after every request completion.\n",
    "    These tweets are in form of data dictionary which is passed to store() function to store it in database.\n",
    "    \n",
    "    parameters:\n",
    "    1.keywords(list):\n",
    "        words to be searched for or for which tweets is to be collected\n",
    "    2.deliminiter(string)\n",
    "        relation between multipe keywords if provided\n",
    "    3.count(int):\n",
    "        number to tweets to be fetched\n",
    "    \n",
    "    returns:\n",
    "    None\n",
    "    \n",
    "    Print numbers of records added to database successfully\n",
    "    \"\"\"\n",
    "    \n",
    "    rec=0\n",
    "    query=percent_encode(get_words(keywords,deliminiter))\n",
    "    q=\"q=%s&result_type=recent&count=100\"%(query)\n",
    "    \n",
    "    while count>0:\n",
    "        count=count-100\n",
    "        result = api.GetSearch(raw_query=q,return_json=True,include_entities=True)\n",
    "        rec=rec+store(result['statuses'])\n",
    "        q=result['search_metadata']['next_results']\n",
    "        q=q[1:len(q)]\n",
    "    \n",
    "    print('{0} Records Added Successfully'.format(rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data fetching through streaming(Note: It is to be used to collect random tweets only, Not an accurate way to search tweets)\n",
    "\n",
    "def streamTweets(keywords=[],deliminiter='and',count=100,language='',filter_level='none'):\n",
    "    \n",
    "    \"\"\"\n",
    "    streamTweets(keywords=[],deliminiter='and',count=100)\n",
    "    \n",
    "    This function fecth the tweets from the twitter's database with stream filter protocol defined by twitter.\n",
    "    Connection will be open with twitter servers until it is closed by api.\n",
    "    These tweets are in form of data dictionary which is passed to store() function to store it in database.\n",
    "    \n",
    "    parameters:\n",
    "    1.keywords(list):\n",
    "        words to be searched for or for which tweets is to be collected\n",
    "    2.deliminiter(string)\n",
    "        relation between multipe keywords if provided\n",
    "    3.count(int):\n",
    "        number to tweets to be fetched\n",
    "    4.languages\n",
    "        options:\n",
    "            en\n",
    "            hi\n",
    "            for more : https://developer.twitter.com/en/docs/developer-utilities/supported-languages/api-reference/get-help-languages\n",
    "    5.filter_level:\n",
    "        Setting this parameter to one of none, low, or medium will set the minimum value of the filter_level Tweet attribute required\n",
    "        to be included in the stream. The default value is none, which includes all available Tweets.\n",
    "    returns:\n",
    "    None\n",
    "    \n",
    "    Print numbers of records added to database successfully\n",
    "    \"\"\"\n",
    "    \n",
    "    rec=0\n",
    "    query=percent_encode(get_words(keywords,deliminiter))\n",
    "    results=api.GetStreamFilter(track=query,filter_level=filter_level,languages=language)\n",
    "    \n",
    "    for var in range(count):\n",
    "        try:\n",
    "            (data,user)=extract(next(results))\n",
    "            rec=rec+add_document(db,data,user)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    results.close()\n",
    "            \n",
    "    print('{0} Records Added Successfully'.format(rec))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store twitter search results to database\n",
    "\n",
    "def store(stats):\n",
    "    \"\"\"\n",
    "    store(stats)\n",
    "    \n",
    "    Iterate over the tweets fetched from twitter database\n",
    "    \n",
    "    parameters:\n",
    "    1.stats(list)\n",
    "        List with certain number of tweets\n",
    "        \n",
    "    returns:\n",
    "    An integer value \n",
    "    \"\"\"\n",
    "    rec=0\n",
    "    for var in range(len(stats)):\n",
    "        (data,user)=extract(stats[var])\n",
    "        rec=rec+add_document(db,data,user)\n",
    "    \n",
    "    return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export to CSV files\n",
    "\n",
    "def exportToCSV(columns=[],details='tweets',filename='twitter'):\n",
    "    \"\"\"\n",
    "    exportToCSV(columns=[],details='tweets',filename='twitter')\n",
    "    \n",
    "    This function is use to export specific details from database to csv file.\n",
    "    This function used DicWriter of csv to write data dictionary to csv file\n",
    "    \n",
    "    1.columns(list)\n",
    "        database key values to be exported to csv file\n",
    "    3.filename\n",
    "        name of csv file\n",
    "        \n",
    "    returns:\n",
    "    None\n",
    "    \n",
    "    Prints status of file completion\n",
    "    \"\"\"\n",
    "    \n",
    "    dct={}\n",
    "    for var in columns:\n",
    "        dct[var]=1\n",
    "    dct['_id']=0\n",
    "    \n",
    "    if  details is 'users':\n",
    "        res=db.users.find({},dct)\n",
    "    else:\n",
    "        res=db.tweets.find({},dct)\n",
    "        \n",
    "    \n",
    "    with open('%s.csv'%filename, 'w') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=columns)\n",
    "        \n",
    "        writer.writeheader()\n",
    "        for va in res:\n",
    "            try:\n",
    "                writer.writerow(va)\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "    \n",
    "    print('Writing complete')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter by date,time and day\n",
    "\n",
    "def filterDateTime(filter_by=None,value1=None,value2=None,flag=None):\n",
    "    \"\"\"\n",
    "    filterTweets(filter_by=None,keywords=None,flag=None,value=None)\n",
    "    \n",
    "    This function is used to filter the tweets fetched from the database on the basis of date\n",
    "    \n",
    "    parameters:\n",
    "    1.filter_by(string):\n",
    "        options:\n",
    "            date\n",
    "            time\n",
    "            day\n",
    "    2.value1(list,string):\n",
    "        Values for the filtering\n",
    "        Note: To be used with following filter options and flag only:\n",
    "            Date\n",
    "            Time\n",
    "            Day\n",
    "                Format:\n",
    "                Date(list):[2018,3,21] i.e. [yyyy,mm,dd]\n",
    "                    Flags:\n",
    "                        et\n",
    "                        gt\n",
    "                        lt\n",
    "                        lte\n",
    "                        gte\n",
    "                        ne\n",
    "                Time(list):[14,2,1] i.e [hh,mm,ss]\n",
    "                    Flags:\n",
    "                        et\n",
    "                        gt\n",
    "                        lt\n",
    "                        lte\n",
    "                        gte\n",
    "                        ne\n",
    "                Day(string):\n",
    "                value options:\n",
    "                        'Mon'\n",
    "                        'Tue'\n",
    "                        'Wed'\n",
    "                        'Thu'\n",
    "                        'Fri'\n",
    "                        'Sat'\n",
    "                        'Sun'\n",
    "    2.value2(list,string):\n",
    "        Values for the filtering\n",
    "        Note: To be used with following filter options only:\n",
    "            Date\n",
    "            Time\n",
    "        Format:\n",
    "            Date(list):[2018,3,21] i.e. [yyyy,mm,dd]\n",
    "            Time(list):[14,2,1] i.e [hh,mm,ss]\n",
    "        Flags:\n",
    "            bt\n",
    "        \n",
    "    4.flag(string):\n",
    "        used with filter with string type values\n",
    "        options:\n",
    "            bt\n",
    "            et\n",
    "            lt\n",
    "            gt\n",
    "            lte\n",
    "            gte\n",
    "            ne\n",
    "         Note: To be used with following filter options only:\n",
    "             Date\n",
    "             Time\n",
    "\n",
    "    returns:\n",
    "    An instance of tweet class\n",
    "    Operations which be perfored on this object\n",
    "    next():\n",
    "        Goto next page of tweet book\n",
    "    previous():\n",
    "        Goto previous page of tweet book  \n",
    "    \"\"\"\n",
    "    \n",
    "    obj=None\n",
    "    filter_b='created_at.%s'%filter_by\n",
    "    \n",
    "    if flag:\n",
    "        sym='$%s'%flag\n",
    "        \n",
    "    try:\n",
    "        if filter_by is 'date' and flag is not 'bt':\n",
    "            value=getDate(value1)\n",
    "        elif filter_by is 'time' and flag is not 'bt':\n",
    "            value=getTime(value1)\n",
    "        elif filter_by is 'day':\n",
    "            value=value1  \n",
    "        elif filter_by is 'date' and flag is 'bt':\n",
    "            value1=getDate(value1)\n",
    "            value2=getDate(value2)\n",
    "        elif filter_by is 'time' and flag is 'bt':\n",
    "            value1=getTime(value1)\n",
    "            value2=getTime(value2)\n",
    "    \n",
    "        if filter_by in ['date','time','day'] and flag is 'et':\n",
    "            data=db.tweets.find({filter_b:value},{'_id':0})\n",
    "        elif filter_by in ['date','time'] and flag in ['gt','lt','lte','gte','ne']:\n",
    "            data=db.tweets.find({filter_b:{sym:value}},{'_id':0})\n",
    "        elif filter_by in ['date','time'] and flag is 'bt':\n",
    "            data=db.tweets.find({filter_b:{'$gt':value1},filter_b:{'$lt':value2}},{'_id':0})\n",
    "        \n",
    "        if data.count()>0:\n",
    "            print('{0} tweets matched'.format(data.count()))\n",
    "            obj=gen_pages(db,data)\n",
    "        else:\n",
    "            print('No tweets found with %s filter'%filter_by)\n",
    "    except Exception as e:\n",
    "        print('%s, Check documentation to see allowed parameter values'%e)\n",
    "        obj=None\n",
    "        \n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get concatinated value for date,time\n",
    "\n",
    "def getDate(dt):\n",
    "    \"\"\"\n",
    "    getDate(dt)\n",
    "    \n",
    "    returns a formated date from the values of list parameter\n",
    "    \"\"\"\n",
    "    date=''\n",
    "    for va in dt:\n",
    "        date+='%s '%va\n",
    "    \n",
    "    return date[0:len(date)-1]\n",
    "\n",
    "def getTime(tm):\n",
    "    \"\"\"\n",
    "    getTime(dt)\n",
    "    \n",
    "    returns a formated time from the values of list parameter\n",
    "    \"\"\"\n",
    "    time=''\n",
    "    for va in tm:\n",
    "        if va is 0 or va is '0' or len(str(va)) is 1:\n",
    "            va='0'+str(va)\n",
    "        time+='%s:'%str(va)\n",
    "    \n",
    "    return time[0:len(time)-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configure API\n",
    "\n",
    "def configure(consumer_key=None,access_token_key=None,consumer_secret=None,access_token_secret=None,uri=None):\n",
    "    \"\"\"\n",
    "    configure(consumer_key=None,access_token_key=None,consumer_secret=None,access_token_secret=None,uri=None)\n",
    "    \n",
    "    Saves the authetication keys to a json file for further initialization process\n",
    "    \n",
    "    parameters:\n",
    "    1.consumer_key(string)\n",
    "    2.access_token_key(string)\n",
    "    3.consumer_secret(string)\n",
    "    4.access_token_secret(string)\n",
    "    \"\"\"\n",
    "    \n",
    "    data={\n",
    "        'keys':{'consumer_key':consumer_key\n",
    "        ,'access_token_key':access_token_key\n",
    "        ,'consumer_secret':consumer_secret\n",
    "        ,'access_token_secret':access_token_secret\n",
    "               }\n",
    "        ,'uri':uri\n",
    "    }\n",
    "    \n",
    "    if not consumer_secret or not consumer_key or not access_token_key or not access_token_secret:\n",
    "        print('In valid authentication tokens')\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        with open('twitter.json', 'w') as outfile:\n",
    "            json.dump(data, outfile)\n",
    "        print('API configured successfully')\n",
    "    except Exception as e:\n",
    "        print('Error in configuring API, %s'%e)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intializing the search/streaming connection\n",
    "\n",
    "def initialize():\n",
    "    \"\"\"\n",
    "    initialize()\n",
    "    \n",
    "    Initializes the api instance using python-twitter library which is used to create conection and fetch tweets\n",
    "    \"\"\"\n",
    "    global api\n",
    "    \n",
    "    try:\n",
    "        if api.chunk_size:\n",
    "            print('API already initialized')\n",
    "            return\n",
    "    except:\n",
    "        None\n",
    "    \n",
    "    \n",
    "    try:\n",
    "    \n",
    "        data=json.load(open('twitter.json'))\n",
    "    \n",
    "        consumer_key=data['keys']['consumer_key']\n",
    "        access_token_key=data['keys']['access_token_key']\n",
    "        consumer_secret=data['keys']['consumer_secret']\n",
    "        access_token_secret=data['keys']['access_token_secret']\n",
    "\n",
    "        api = twitter.Api(consumer_key=consumer_key,\n",
    "                      consumer_secret=consumer_secret,\n",
    "                      access_token_key=access_token_key,\n",
    "                      access_token_secret=access_token_secret)\n",
    "        \n",
    "        database()\n",
    "        par()\n",
    "        \n",
    "        print('API intialized')\n",
    "    except Exception as e:\n",
    "        print('Error in intializing API, Run configure() first %s'%e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verifying intialization\n",
    "\n",
    "def verify():\n",
    "    \"\"\"\n",
    "    verify():\n",
    "    \n",
    "    Prints the details of user for verifcation purpose\n",
    "    \"\"\"\n",
    "    pp.pprint(api.VerifyCredentials())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View tweet book page\n",
    "\n",
    "def viewBook(book):\n",
    "    \"\"\"\n",
    "    viewBook(book)\n",
    "    \n",
    "    parameter:\n",
    "    1.book\n",
    "        Instance of tweetBook\n",
    "    \n",
    "    Prints the tweets in single page\n",
    "    \"\"\"\n",
    "    \n",
    "    pp.pprint(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export filtered data to csv file\n",
    "\n",
    "def exportFilter(book,cols=[],filename='filterTwitter'):\n",
    "    \"\"\"\n",
    "    exportFilter(book,cols=[],filename='filterTwitter')\n",
    "    \n",
    "    Export the filtered tweets to the csv file\n",
    "    \n",
    "    parameters:\n",
    "    1.book:\n",
    "        Instance of tweetBook class\n",
    "    2.filename(string)\n",
    "        name of csv file\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    col=cols\n",
    "    data=[]\n",
    "    \n",
    "    for var in range(book.pages):\n",
    "        dat=book.data[var]['tweets']\n",
    "        for var in dat:\n",
    "            tmp={}\n",
    "            for va in col:\n",
    "                try:\n",
    "                    tmp[va]=var[va]\n",
    "                except:\n",
    "                    print('Enter valid column names, See documentation for further details')\n",
    "                    return\n",
    "            data.append(tmp)\n",
    "    \n",
    "    with open('%s.csv'%filename, 'w') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=col)\n",
    "        \n",
    "        writer.writeheader()\n",
    "        for va in data:\n",
    "            try:\n",
    "                #print(va)\n",
    "                writer.writerow(va)\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "    \n",
    "    print('Writing complete')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'by nikhil singh bisht\\n    email:nikhilsinghbisht21@gmailcom\\n    git:github.com/nikhilbisht21 \\n    linkden:linkedin.com/in/Nikhil-bisht-155947132/\\n    Date:3/23/2018\\n    '"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"by nikhil singh bisht\n",
    "    email:nikhilsinghbisht21@gmailcom\n",
    "    git:github.com/nikhilbisht21 \n",
    "    linkden:linkedin.com/in/Nikhil-bisht-155947132/\n",
    "    Date:3/23/2018\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter object values\n",
    "\n",
    "created_at<br>\n",
    "id<br>\n",
    "id_str<br>\n",
    "text<br>\n",
    "truncated<br>\n",
    "entities<br>\n",
    "\thashtags<br>\n",
    "\tsymbols<br>\n",
    "\tuser_mentiovns<br>\n",
    "\turls<br>\n",
    "\tmedia<br>\n",
    "extended_entities<br>\n",
    "\tmedia<br>\n",
    "metadata<br>\n",
    "\tiso_language_code<br>\n",
    "\tresult_type<br>\n",
    "source<br>\n",
    "in_reply_to_status_id<br>\n",
    "in_reply_to_status_id_str<br>\n",
    "in_reply_to_user_id<br>\n",
    "in_reply_to_user_id_str<br>\n",
    "in_reply_to_screen_name<br>\n",
    "user<br>\n",
    "\tid<br>\n",
    "\tid_str<br>\n",
    "\tname<br>\n",
    "\tscreen_name<br>\n",
    "\tlocation<br>\n",
    "\tdescription<br>\n",
    "\turl<br>\n",
    "\tentities<br>\n",
    "\tdescription<br>\n",
    "\turls<br>\n",
    "\tprotected<br>\n",
    "\tfollowers_count<br>\n",
    "\tfriends_count<br>\n",
    "\tlisted_count<br>\n",
    "\tcreated_at<br>\n",
    "\tfavourites_count<br>\n",
    "\tutc_offset<br>\n",
    "\ttime_zone<br>\n",
    "\tgeo_enabled<br>\n",
    "\tverified<br>\n",
    "\tstatuses_count<br>\n",
    "\tlang<br>\n",
    "\tcontributors_enabled<br>\n",
    "\tis_translator<br>\n",
    "\tis_translation_enabled<br>\n",
    "\tprofile_background_color<br>\n",
    "\tprofile_background_image_url<br>\n",
    "\tprofile_background_image_url_https<br>\n",
    "\tprofile_background_tile<br>\n",
    "\tprofile_image_url<br>\n",
    "\tprofile_image_url_https<br>\n",
    "\tprofile_banner_url<br>\n",
    "\tprofile_link_color<br>\n",
    "\tprofile_sidebar_border_color<br>\n",
    "\tprofile_sidebar_fill_color<br>\n",
    "\tprofile_text_color<br>\n",
    "\tprofile_use_background_image<br>\n",
    "\thas_extended_profile<br>\n",
    "\tdefault_profile<br>\n",
    "\tdefault_profile_image<br>\n",
    "\tfollowing<br>\n",
    "\tfollow_request_sent<br>\n",
    "\tnotifications<br>\n",
    "\ttranslator_type<br>\n",
    "geo<br>\n",
    "coordinates<br>\n",
    "place<br>\n",
    "contributors<br>\n",
    "retweeted_status<br>\n",
    "\tcreated_at<br>\n",
    "\tid<br>\n",
    "\tid_str<br>\n",
    "\ttext<br>\n",
    "\ttruncated<br>\n",
    "\tentities<br>\n",
    "\thashtags<br>\n",
    "\tsymbols<br>\n",
    "\tuser_mentions<br>\n",
    "\turls<br>\n",
    "\tmedia<br>\n",
    "\textended_entities<br>\n",
    "\tmedia<br>\n",
    "\tmetadata<br>\n",
    "\tiso_language_code<br>\n",
    "\tresult_type<br>\n",
    "\tsource<br>\n",
    "\tin_reply_to_status_id<br>\n",
    "\tin_reply_to_status_id_str<br>\n",
    "\tin_reply_to_user_id<br>\n",
    "\tin_reply_to_user_id_str<br>\n",
    "\tin_reply_to_screen_name<br>\n",
    "\tuser<br>\n",
    "\tid<br>\n",
    "\tid_str<br>\n",
    "\tname<br>\n",
    "\tscreen_name<br>\n",
    "\tlocation<br>\n",
    "\tdescription<br>\n",
    "\turl<br>\n",
    "\tentities<br>\n",
    "\tdescription<br>\n",
    "\turls<br>\n",
    "\tprotected<br>\n",
    "\tfollowers_count<br>\n",
    "\tfriends_count<br>\n",
    "\tlisted_count<br>\n",
    "\tcreated_at<br>\n",
    "\tfavourites_count<br>\n",
    "\tutc_offset<br>\n",
    "\ttime_zone<br>\n",
    "\tgeo_enabled<br>\n",
    "\tverified<br>\n",
    "\tstatuses_count<br>\n",
    "\tlang<br>\n",
    "\tcontributors_enabled<br>\n",
    "\tis_translator<br>\n",
    "\tis_translation_enabled<br>\n",
    "\tprofile_background_color<br>\n",
    "\tprofile_background_image_url<br>\n",
    "\tprofile_background_image_url_https<br>\n",
    "\tprofile_background_tile<br>\n",
    "\tprofile_image_url<br>\n",
    "\tprofile_image_url_https<br>\n",
    "\tprofile_banner_url<br>\n",
    "\tprofile_link_color<br>\n",
    "\tprofile_sidebar_border_color<br>\n",
    "\tprofile_sidebar_fill_color<br>\n",
    "\tprofile_text_color<br>\n",
    "\tprofile_use_background_image<br>\n",
    "\thas_extended_profile<br>\n",
    "\tdefault_profile<br>\n",
    "\tdefault_profile_image<br>\n",
    "\tfollowing<br>\n",
    "\tfollow_request_sent<br>\n",
    "\tnotifications<br>\n",
    "\ttranslator_type<br>\n",
    "\tgeo<br>\n",
    "\tcoordinates<br>\n",
    "\tplace<br>\n",
    "\tcontributors<br>\n",
    "\tis_quote_status<br>\n",
    "\tretweet_count<br>\n",
    "\tfavorite_count<br>\n",
    "\tfavorited<br>\n",
    "\tretweeted<br>\n",
    "\tpossibly_sensitive<br>\n",
    "\tlang<br>\n",
    "is_quote_status<br>\n",
    "retweet_count<br>\n",
    "favorite_count<br>\n",
    "favorited<br>\n",
    "retweeted<br>\n",
    "possibly_sensitive<br>\n",
    "lang<br>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
